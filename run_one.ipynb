{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4601 rows, 24 features from spambase_binarized.csv\n",
      "null\n",
      "Finding Optimal Objective...\n",
      "treefarms reported successful execution\n",
      "{\n",
      "  \"false\": {\n",
      "    \"false\": {\n",
      "      \"false\": {\n",
      "        \"complexity\": 0.004999999888241291,\n",
      "        \"loss\": 0.0028254727367311716,\n",
      "        \"name\": \"label\",\n",
      "        \"prediction\": 0\n",
      "      },\n",
      "      \"feature\": 9,\n",
      "      \"name\": \"word_freq_hp <= 0.11999999731779099\",\n",
      "      \"reference\": 1,\n",
      "      \"relation\": \"==\",\n",
      "      \"true\": {\n",
      "        \"complexity\": 0.004999999888241291,\n",
      "        \"loss\": 0.017387524247169495,\n",
      "        \"name\": \"label\",\n",
      "        \"prediction\": 1\n",
      "      },\n",
      "      \"type\": \"integral\"\n",
      "    },\n",
      "    \"feature\": 5,\n",
      "    \"name\": \"word_freq_free <= 0.13499999791383743\",\n",
      "    \"reference\": 1,\n",
      "    \"relation\": \"==\",\n",
      "    \"true\": {\n",
      "      \"false\": {\n",
      "        \"complexity\": 0.004999999888241291,\n",
      "        \"loss\": 0.010432515293359756,\n",
      "        \"name\": \"label\",\n",
      "        \"prediction\": 1\n",
      "      },\n",
      "      \"feature\": 14,\n",
      "      \"name\": \"char_freq_! <= 0.3774999976158142\",\n",
      "      \"reference\": 1,\n",
      "      \"relation\": \"==\",\n",
      "      \"true\": {\n",
      "        \"false\": {\n",
      "          \"false\": {\n",
      "            \"complexity\": 0.004999999888241291,\n",
      "            \"loss\": 0.0017387524712830782,\n",
      "            \"name\": \"label\",\n",
      "            \"prediction\": 0\n",
      "          },\n",
      "          \"feature\": 9,\n",
      "          \"name\": \"word_freq_hp <= 0.11999999731779099\",\n",
      "          \"reference\": 1,\n",
      "          \"relation\": \"==\",\n",
      "          \"true\": {\n",
      "            \"complexity\": 0.004999999888241291,\n",
      "            \"loss\": 0.0091284504160285,\n",
      "            \"name\": \"label\",\n",
      "            \"prediction\": 1\n",
      "          },\n",
      "          \"type\": \"integral\"\n",
      "        },\n",
      "        \"feature\": 15,\n",
      "        \"name\": \"char_freq_$ <= 0.012500000186264515\",\n",
      "        \"reference\": 1,\n",
      "        \"relation\": \"==\",\n",
      "        \"true\": {\n",
      "          \"false\": {\n",
      "            \"complexity\": 0.004999999888241291,\n",
      "            \"loss\": 0.0036948490887880325,\n",
      "            \"name\": \"label\",\n",
      "            \"prediction\": 1\n",
      "          },\n",
      "          \"feature\": 2,\n",
      "          \"name\": \"word_freq_remove <= 0.044999999925494194\",\n",
      "          \"reference\": 1,\n",
      "          \"relation\": \"==\",\n",
      "          \"true\": {\n",
      "            \"complexity\": 0.004999999888241291,\n",
      "            \"loss\": 0.02477722242474556,\n",
      "            \"name\": \"label\",\n",
      "            \"prediction\": 0\n",
      "          },\n",
      "          \"type\": \"integral\"\n",
      "        },\n",
      "        \"type\": \"integral\"\n",
      "      },\n",
      "      \"type\": \"integral\"\n",
      "    },\n",
      "    \"type\": \"integral\"\n",
      "  },\n",
      "  \"feature\": 22,\n",
      "  \"model_objective\": 0.14019668102264404,\n",
      "  \"name\": \"capital_run_length_longest <= 9.5\",\n",
      "  \"reference\": 1,\n",
      "  \"relation\": \"==\",\n",
      "  \"true\": {\n",
      "    \"false\": {\n",
      "      \"complexity\": 0.004999999888241291,\n",
      "      \"loss\": 0.0013040644116699696,\n",
      "      \"name\": \"label\",\n",
      "      \"prediction\": 1\n",
      "    },\n",
      "    \"feature\": 1,\n",
      "    \"name\": \"word_freq_remove <= 0.009999999776482582\",\n",
      "    \"reference\": 1,\n",
      "    \"relation\": \"==\",\n",
      "    \"true\": {\n",
      "      \"complexity\": 0.004999999888241291,\n",
      "      \"loss\": 0.023907845839858055,\n",
      "      \"name\": \"label\",\n",
      "      \"prediction\": 0\n",
      "    },\n",
      "    \"type\": \"integral\"\n",
      "  },\n",
      "  \"type\": \"integral\"\n",
      "}\n",
      "{\n",
      "  \"false\": {\n",
      "    \"false\": {\n",
      "      \"false\": {\n",
      "        \"complexity\": 0.004999999888241291,\n",
      "        \"loss\": 0.0028254727367311716,\n",
      "        \"name\": \"label\",\n",
      "        \"prediction\": 0\n",
      "      },\n",
      "      \"feature\": 9,\n",
      "      \"name\": \"word_freq_hp <= 0.11999999731779099\",\n",
      "      \"reference\": 1,\n",
      "      \"relation\": \"==\",\n",
      "      \"true\": {\n",
      "        \"complexity\": 0.004999999888241291,\n",
      "        \"loss\": 0.017387524247169495,\n",
      "        \"name\": \"label\",\n",
      "        \"prediction\": 1\n",
      "      },\n",
      "      \"type\": \"integral\"\n",
      "    },\n",
      "    \"feature\": 5,\n",
      "    \"name\": \"word_freq_free <= 0.13499999791383743\",\n",
      "    \"reference\": 1,\n",
      "    \"relation\": \"==\",\n",
      "    \"true\": {\n",
      "      \"false\": {\n",
      "        \"complexity\": 0.004999999888241291,\n",
      "        \"loss\": 0.010432515293359756,\n",
      "        \"name\": \"label\",\n",
      "        \"prediction\": 1\n",
      "      },\n",
      "      \"feature\": 14,\n",
      "      \"name\": \"char_freq_! <= 0.3774999976158142\",\n",
      "      \"reference\": 1,\n",
      "      \"relation\": \"==\",\n",
      "      \"true\": {\n",
      "        \"false\": {\n",
      "          \"false\": {\n",
      "            \"complexity\": 0.004999999888241291,\n",
      "            \"loss\": 0.0017387524712830782,\n",
      "            \"name\": \"label\",\n",
      "            \"prediction\": 0\n",
      "          },\n",
      "          \"feature\": 9,\n",
      "          \"name\": \"word_freq_hp <= 0.11999999731779099\",\n",
      "          \"reference\": 1,\n",
      "          \"relation\": \"==\",\n",
      "          \"true\": {\n",
      "            \"complexity\": 0.004999999888241291,\n",
      "            \"loss\": 0.0091284504160285,\n",
      "            \"name\": \"label\",\n",
      "            \"prediction\": 1\n",
      "          },\n",
      "          \"type\": \"integral\"\n",
      "        },\n",
      "        \"feature\": 15,\n",
      "        \"name\": \"char_freq_$ <= 0.012500000186264515\",\n",
      "        \"reference\": 1,\n",
      "        \"relation\": \"==\",\n",
      "        \"true\": {\n",
      "          \"false\": {\n",
      "            \"complexity\": 0.004999999888241291,\n",
      "            \"loss\": 0.0036948490887880325,\n",
      "            \"name\": \"label\",\n",
      "            \"prediction\": 1\n",
      "          },\n",
      "          \"feature\": 2,\n",
      "          \"name\": \"word_freq_remove <= 0.044999999925494194\",\n",
      "          \"reference\": 1,\n",
      "          \"relation\": \"==\",\n",
      "          \"true\": {\n",
      "            \"complexity\": 0.004999999888241291,\n",
      "            \"loss\": 0.02477722242474556,\n",
      "            \"name\": \"label\",\n",
      "            \"prediction\": 0\n",
      "          },\n",
      "          \"type\": \"integral\"\n",
      "        },\n",
      "        \"type\": \"integral\"\n",
      "      },\n",
      "      \"type\": \"integral\"\n",
      "    },\n",
      "    \"type\": \"integral\"\n",
      "  },\n",
      "  \"feature\": 22,\n",
      "  \"model_objective\": 0.14019668102264404,\n",
      "  \"name\": \"capital_run_length_longest <= 9.5\",\n",
      "  \"reference\": 1,\n",
      "  \"relation\": \"==\",\n",
      "  \"true\": {\n",
      "    \"false\": {\n",
      "      \"complexity\": 0.004999999888241291,\n",
      "      \"loss\": 0.0013040644116699696,\n",
      "      \"name\": \"label\",\n",
      "      \"prediction\": 1\n",
      "    },\n",
      "    \"feature\": 2,\n",
      "    \"name\": \"word_freq_remove <= 0.044999999925494194\",\n",
      "    \"reference\": 1,\n",
      "    \"relation\": \"==\",\n",
      "    \"true\": {\n",
      "      \"complexity\": 0.004999999888241291,\n",
      "      \"loss\": 0.023907845839858055,\n",
      "      \"name\": \"label\",\n",
      "      \"prediction\": 0\n",
      "    },\n",
      "    \"type\": \"integral\"\n",
      "  },\n",
      "  \"type\": \"integral\"\n",
      "}\n",
      "training completed. Number of trees in the Rashomon set: 8951989\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse, time, math, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "from resplit import RESPLIT\n",
    "from licketyresplit import LicketyRESPLIT\n",
    "from treefarms import TREEFARMS\n",
    "from gosdt import GOSDTClassifier\n",
    "\n",
    "\n",
    "\n",
    "## TreeFARMS Attempts\n",
    "def structurally_equal(a, b):\n",
    "    if type(a) != type(b):\n",
    "        return False\n",
    "    if hasattr(a, \"prediction\") and hasattr(b, \"prediction\"):\n",
    "        return a.prediction == b.prediction\n",
    "    if hasattr(a, \"feature\") and hasattr(b, \"feature\"):\n",
    "        return (a.feature == b.feature and\n",
    "                structurally_equal(a.left_child, b.left_child) and\n",
    "                structurally_equal(a.right_child, b.right_child))\n",
    "    return False\n",
    "\n",
    "def tree_structure_signature(tree):  # hashable nested tuples\n",
    "    if hasattr(tree, \"prediction\"):\n",
    "        return ('leaf', int(tree.prediction))\n",
    "    if hasattr(tree, \"feature\"):\n",
    "        return ('node',\n",
    "                int(tree.feature),\n",
    "                tree_structure_signature(tree.left_child),\n",
    "                tree_structure_signature(tree.right_child))\n",
    "    raise ValueError(f\"Unknown tree type: {type(tree)}\")\n",
    "\n",
    "def _collect_trees_from_treefarms(model, max_try=10000000):\n",
    "    trees, i = [], 0\n",
    "    while i < max_try:\n",
    "        try:\n",
    "            t = model[i]\n",
    "        except Exception:\n",
    "            break\n",
    "        trees.append(t)\n",
    "        i += 1\n",
    "   \n",
    "    return trees\n",
    "\n",
    "def _tree_errors(tree, X, y):\n",
    "    N = len(y)\n",
    "    if hasattr(tree, \"score\"):\n",
    "        acc = float(tree.score(X, y))\n",
    "        return int(round((1.0 - acc) * N)), acc\n",
    "    raise RuntimeError(\"Tree does not expose .score(X,y)\")\n",
    "\n",
    "def _num_leaves(tree):\n",
    "    if hasattr(tree, \"leaves\"):\n",
    "        return int(getattr(tree, \"leaves\")())\n",
    "    raise RuntimeError(\"Tree does not expose leaves()/num_leaves().\")\n",
    "\n",
    "def summarize_treefarms_objectives(model, X, y, reg, epsilon=0.01):\n",
    "    trees = _collect_trees_from_treefarms(model)\n",
    "    if not trees:\n",
    "        raise RuntimeError(\"No trees retrieved from TREEFARMS (indexing/iter failed).\")\n",
    "\n",
    "    N = len(y)\n",
    "    lamN = int(round(float(reg) * N))\n",
    "\n",
    "    objs, err_list, leaf_list, acc_list = [], [], [], []\n",
    "    for i, t in enumerate(trees):\n",
    "        errs, acc = _tree_errors(t, X, y)\n",
    "        leaves = _num_leaves(t)\n",
    "        obj = errs + lamN * leaves\n",
    "        objs.append(obj)\n",
    "        err_list.append(errs)\n",
    "        leaf_list.append(leaves)\n",
    "        acc_list.append(acc)\n",
    "\n",
    "    objs = np.asarray(objs, dtype=float)\n",
    "    min_obj = float(np.min(objs))\n",
    "    max_obj = float(np.max(objs))\n",
    "    add_gap = max_obj - min_obj\n",
    "    multiplicative_range = max_obj / min_obj # = 1 + x\n",
    "    x = multiplicative_range - 1.0 # solve min*(1+x)=max\n",
    "\n",
    "    cutoff = (1.0 + float(epsilon)) * min_obj\n",
    "    passing_idx = [i for i, v in enumerate(objs) if v <= cutoff]\n",
    "\n",
    "    print(\"\\n[TREEFARMS Objective Summary]\")\n",
    "    print(f\"trees: {len(trees)} | N: {N} | reg: {reg} | lamN: {lamN}\")\n",
    "    print(f\"min_objective: {int(min_obj)}  |  max_objective: {int(max_obj)}\")\n",
    "    print(f\"additive_gap (max - min): {int(add_gap)}\")\n",
    "    print(f\"multiplicative_range = max/min = {multiplicative_range:.6f}  (x such that min*(1+x)=max is x = {x:.6f})\")\n",
    "    print(f\"epsilon: {epsilon} | cutoff = min*(1+epsilon) = {cutoff:.6f}\")\n",
    "    print(f\"trees within cutoff: {len(passing_idx)}  |  indices: {passing_idx}\")\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(objs, bins=20, color='skyblue', edgecolor='black')\n",
    "    plt.axvline(min_obj, color='green', linestyle='--', label='min objective')\n",
    "    plt.axvline(cutoff, color='red', linestyle='--', label='(1 + ε) · min')\n",
    "    plt.axvline(min_obj + epsilon * N, color='purple', linestyle='--', label='min + ε · N')\n",
    "\n",
    "    plt.title(\"Histogram of TREEFARMS Objectives\")\n",
    "    plt.xlabel(\"Objective value (errors + λN·leaves)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    objs_normalized = [obj / N for obj in objs]\n",
    "    min_obj_norm = min_obj / N\n",
    "    cutoff_norm = cutoff / N\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(objs_normalized, bins=20, color='lightcoral', edgecolor='black')\n",
    "    plt.axvline(min_obj_norm, color='green', linestyle='--', label='min objective')\n",
    "    plt.axvline(cutoff_norm, color='red', linestyle='--', label='(1 + ε) · min')\n",
    "\n",
    "    plt.title(\"Histogram of TREEFARMS Objectives (Normalized by N [Standard Formulation])\")\n",
    "    plt.xlabel(\"Normalized Objective (misclassification_prop + λ·leaves)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"num_trees\": len(trees),\n",
    "        \"lamN\": lamN,\n",
    "        \"min_objective\": min_obj,\n",
    "        \"max_objective\": max_obj,\n",
    "        \"additive_gap\": add_gap,\n",
    "        \"multiplicative_range\": multiplicative_range,  # equals 1 + x\n",
    "        \"x\": x,\n",
    "        \"epsilon\": float(epsilon),\n",
    "        \"cutoff\": cutoff,\n",
    "        \"passing_indices\": passing_idx,\n",
    "        \"per_tree\": [\n",
    "            {\"index\": i, \"objective\": int(objs[i]), \"errors\": int(err_list[i]),\n",
    "             \"leaves\": int(leaf_list[i]), \"accuracy\": float(acc_list[i])}\n",
    "            for i in range(len(trees))\n",
    "        ],\n",
    "    }\n",
    "\n",
    "## End TreeFARMS Attempts\n",
    "\n",
    "# -------------- helpers --------------\n",
    "\n",
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path)\n",
    "    X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "    print(f\"Loaded {df.shape[0]} rows, {df.shape[1]-1} features from {path}\")\n",
    "    return X, y\n",
    "\n",
    "def fit_gosdt_get_objective(X, y, reg, depth_budget=5, verbose=False):\n",
    "    \"\"\"Returns reg*#leaves + model_loss from GOSDT at the given depth.\"\"\"\n",
    "    clf = GOSDTClassifier(\n",
    "        regularization=reg,\n",
    "        time_limit=6000,\n",
    "        depth_budget=int(depth_budget),\n",
    "        verbose=verbose\n",
    "    )\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    model_loss = clf.result_.model_loss\n",
    "    raw_model = clf.result_.model\n",
    "\n",
    "    def count_leaves(node):\n",
    "        if isinstance(node, str):\n",
    "            node = json.loads(node)\n",
    "        if isinstance(node, list):\n",
    "            return count_leaves(node[0])\n",
    "        if \"true\" not in node and \"false\" not in node:\n",
    "            return 1\n",
    "        return sum(count_leaves(node[br]) for br in (\"true\",\"false\") if br in node)\n",
    "\n",
    "    n_leaves = count_leaves(raw_model)\n",
    "    return model_loss + reg * n_leaves\n",
    "\n",
    "def run_resplit(X, y, reg, mult, depth):\n",
    "    # RESPLIT inherits TREEFARMS' depth convention (root depth = 1)\n",
    "    depth_tf = depth + 1\n",
    "    config = {\n",
    "        \"regularization\": reg,\n",
    "        \"rashomon_bound_multiplier\": mult,\n",
    "        \"depth_budget\": depth_tf,\n",
    "        \"cart_lookahead_depth\": math.ceil((depth_tf-1) / 2),\n",
    "        \"verbose\": False\n",
    "    }\n",
    "    model = RESPLIT(config, fill_tree=\"treefarms\")\n",
    "    t0 = time.perf_counter()\n",
    "    model.fit(X, y)\n",
    "    dt = time.perf_counter() - t0\n",
    "    n_trees = len(model)\n",
    "    label = \"RESPLIT-treefarms\"\n",
    "    return dt, n_trees, label, model\n",
    "\n",
    "def run_lickety(X, y, reg, mult, depth, best_objective=None, lookahead=1, prune_style=\"Z\", consistent_lookahead=True, better_than_greedy=False, try_greedy_first=False, trie_cache_strategy = \"compact\", multiplicative_slack=0):\n",
    "    config = {\n",
    "        \"regularization\": reg,\n",
    "        \"rashomon_bound_multiplier\": mult,\n",
    "        \"depth_budget\": depth,\n",
    "    }\n",
    "    if best_objective is not None:\n",
    "        config[\"best_objective\"] = best_objective\n",
    "    model = LicketyRESPLIT(config, multipass=True, lookahead=int(lookahead), optimal=False, pruning=True, prune_style=prune_style, consistent_lookahead=consistent_lookahead, better_than_greedy=better_than_greedy, try_greedy_first=try_greedy_first, trie_cache_strategy = trie_cache_strategy, multiplicative_slack=multiplicative_slack)\n",
    "    t0 = time.perf_counter()\n",
    "    model.fit(X, y)\n",
    "    dt = time.perf_counter() - t0\n",
    "    n_trees = model.count_trees()\n",
    "    print(f\"Found {model.trie.count_trees()} trees but truncated to {n_trees}\")\n",
    "    label = f\"LicketyRESPLIT[lookahead={lookahead}{prune_style}, best={'gosdt' if best_objective is not None else 'lickety'}]\"\n",
    "    return dt, n_trees, label, model\n",
    "\n",
    "def run_treefarms(X, y, reg, mult, depth):\n",
    "    config = {\n",
    "        \"regularization\": reg,\n",
    "        \"rashomon_bound_multiplier\": mult,\n",
    "        \"depth_budget\": depth + 1,  # TF counts a single leaf as depth 1\n",
    "        \"verbose\": False\n",
    "    }\n",
    "    model = TREEFARMS(config)\n",
    "    t0 = time.perf_counter()\n",
    "    model.fit(X, y)\n",
    "    dt = time.perf_counter() - t0\n",
    "    if hasattr(model, \"get_tree_count\"):\n",
    "        n_trees = model.get_tree_count()\n",
    "    elif hasattr(model, \"__len__\"):\n",
    "        n_trees = len(model)\n",
    "    else:\n",
    "        n_trees = None\n",
    "    label = \"TREEFARMS\"\n",
    "\n",
    "    stats = summarize_treefarms_objectives(model, X, y, reg=reg, epsilon=mult)\n",
    "    return dt, n_trees, label, model\n",
    "\n",
    "# -------------- main --------------\n",
    "def main(data_path, algo=\"lickety\", reg=0.01, depth=10, mult=0.01, use_gosdt_objective=False, better_than_greedy = False, lookahead_k = 1, prune_style = \"H\", consistent_lookahead=False, try_greedy_first=False, trie_cache_strategy = \"compact\", multiplicative_slack=0.00):\n",
    "\n",
    "    # =======================================\n",
    "\n",
    "    X, y = load_dataset(data_path)\n",
    "\n",
    "    if algo == \"resplit\":\n",
    "        target = run_resplit\n",
    "        kwargs = dict(X=X, y=y, reg=reg, mult=mult, depth=depth)\n",
    "\n",
    "    elif algo == \"lickety\":\n",
    "        best_obj = None\n",
    "        if use_gosdt_objective:\n",
    "            print(\"Computing GOSDT objective as baseline...\")\n",
    "            best_obj = fit_gosdt_get_objective(X, y, reg=reg, depth_budget=depth)\n",
    "            #best_obj = 702\n",
    "            print(f\"GOSDT objective: {best_obj:.6f}\")\n",
    "\n",
    "        X_arr = X.to_numpy(copy=False) if hasattr(X, \"to_numpy\") else np.asarray(X)\n",
    "        y_arr = y.to_numpy(copy=False) if hasattr(y, \"to_numpy\") else np.asarray(y)\n",
    "        X_bool = np.asfortranarray(X_arr != 0)\n",
    "        y_uint8 = np.ascontiguousarray((y_arr != 0).astype(np.uint8, copy=False))\n",
    "        del X, y, X_arr, y_arr\n",
    "        gc.collect()\n",
    "        target = run_lickety\n",
    "        kwargs = dict(X=X_bool, y=y_uint8, reg=reg, mult=mult, depth=depth, best_objective=best_obj, lookahead=lookahead_k, prune_style=prune_style, consistent_lookahead=consistent_lookahead, better_than_greedy=better_than_greedy, try_greedy_first=try_greedy_first, trie_cache_strategy = trie_cache_strategy, multiplicative_slack=multiplicative_slack)\n",
    "\n",
    "    elif algo == \"treefarms\":\n",
    "        target = run_treefarms\n",
    "        kwargs = dict(X=X, y=y, reg=reg, mult=mult, depth=depth)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown algo: {algo}\")\n",
    "\n",
    "    baseline_mb = memory_usage(-1, interval=0.05, timeout=1)[0]\n",
    "    # Measure peak RSS during the call (includes child processes if any)\n",
    "    peak_mb, retval = memory_usage(\n",
    "        (target, (), kwargs),\n",
    "        max_usage=True,\n",
    "        retval=True,\n",
    "        interval=0.01,\n",
    "        include_children=True\n",
    "    )\n",
    "    delta_mb = peak_mb - baseline_mb\n",
    "    duration_s, n_trees, label, model = retval\n",
    "\n",
    "    if algo == \"lickety\":\n",
    "        trie = model.trie\n",
    "        num_unique = trie.count_unique_prediction_vectors(X=X_bool)\n",
    "        print(f\"Number of unique predicting trees : {num_unique}\")\n",
    "\n",
    "        keys = sorted(trie.objectives)\n",
    "        total = sum(trie.objectives.values())\n",
    "        min_obj, max_obj = keys[0], keys[-1]\n",
    "        mean_obj = sum(k * c for k, c in trie.objectives.items()) / total\n",
    "        print(f\"objective_stats     : min={min_obj} mean={mean_obj:.3f} max={max_obj}\")\n",
    "\n",
    "      \n",
    "        print(f\"best_objective      : {model.best}\")\n",
    "        print(f\"rashomon_obj_bound  : {model.obj_bound}\")\n",
    "\n",
    "\n",
    "    print(\"\\n=== RESULT ===\")\n",
    "    print(f\"algo               : {label}\")\n",
    "    print(f\"data               : {data_path}\")\n",
    "    print(f\"reg (lambda)       : {reg}\")\n",
    "    print(f\"depth              : {depth}\")\n",
    "    print(f\"rashomon_mult      : {mult}\")\n",
    "    if algo == \"lickety\":\n",
    "        print(f\"lookahead   : {lookahead_k}\")\n",
    "        print(f\"use_gosdt_objective: {use_gosdt_objective}\")\n",
    "    print(f\"time_sec           : {duration_s:.4f}\")\n",
    "    print(f\"peak_rss_mb        : {peak_mb:.1f}\")\n",
    "    print(f\"delta_rss_mb        : {delta_mb:.1f}\")\n",
    "    print(f\"num_trees          : {n_trees}\")\n",
    "\n",
    "    return duration_s, peak_mb, delta_mb, n_trees\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"spambase_binarized.csv\", \"treefarms\", reg=0.005, depth=5, mult=0.01, lookahead_k=1, prune_style=\"H\", consistent_lookahead=False, better_than_greedy=False, use_gosdt_objective=False, try_greedy_first=False, trie_cache_strategy = \"compact\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rashomon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
